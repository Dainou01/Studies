% !TEX program = xelatex
% vim:foldmethod=marker:foldmarker=<<<,>>>
\documentclass[compress]{beamer}

%<<< Preamble
\usepackage[english]{babel}
\usepackage{metalogo}
\usepackage{listings}
\usepackage{fontspec}
\usepackage{amsmath, amssymb}
\usepackage{stackrel}
\usepackage{tikz}
\usepackage{svg}
\usepackage{unicode-math}
\usepackage{subcaption}
\usepackage[theme=nord,charsperline=60,linenumbers]{jlcode}

\usetheme{Nord}

\setmainfont{Roboto}
% \setsansfont{DejaVu Serif}
% \setmonofont{CaskaydiaCove Nerd Font Mono}
\setmonofont{JuliaMono}

\setbeamercolor{mybullet}{use=itemize item.fg,bg=itemize item.fg,fg=itemize item.fg}

\makeatletter
\def\verbatim@nolig@list{}
\newcommand\pin{%
\parbox[t]{10pt}{\raisebox{0.2pt}{\usebeamercolor[fg]{mybullet}{$\ast$}}}}
\makeatother

\newcommand{\E}[1]{\ensuremath{E\left\{#1\right\}}}

\hypersetup{
    colorlinks=true,
    urlcolor=NordBlue
}

\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\Var}{Var}

\AtBeginDocument{
    \fontsize{8}{12}
    \selectfont

}

\AtBeginSection[]
{
    \begin{frame}[c,noframenumbering,plain]
        \tableofcontents[sectionstyle=show/hide,subsectionstyle=show/show/hide]
    \end{frame}
}


\AtBeginSubsection[]
{
    \begin{frame}[c,noframenumbering,plain]
        \tableofcontents[sectionstyle=show/hide,subsectionstyle=show/shaded/hide]
    \end{frame}
}
%>>>

\title{Project II: Estimation Theory}
\subtitle{Maximum likelihood, CRLB \& Least Squares Estimation}
\author{\Large Simon Andreas Bjørn}
\date{\large February 28, 2023}

\begin{document}

\begin{frame}[plain,noframenumbering]
    \maketitle
\end{frame}

\begin{frame} % <<< 1A.1
    \frametitle{Maximum Likelihood Estimator}
    We want to derive the maximum likelihod esimator for the time delay of a pulse
    in additive gaussian noise. The sent pulse $s(t)$ is received as $x(t)$ after
    the time delay $\tau_0 = 2r/c$ which is what we want to estimate.
    \medskip
    \begin{columns}[t]
        \begin{column}{0.4\textwidth}
            \centerline{Model for continues signal}
            \begin{equation*}
                x(t) = s(t-\tau_0) + W(t)
            \end{equation*}

            \begin{itemize}
                \item $W(t)$ = AGN
                \item $s(t-\tau_0)$ = received signal. 
                \item Assume $W$ is bandlimited by $B_w$.
                \item Sample $W(t)$ with $\Delta=\frac{1}{2}B_w$ s.t. $W[n]=W(n\Delta)$.
                \item Sampeling the entire noise bandwidth, we can assume the noise to be
                white. 
            \end{itemize}
        \end{column}
        \begin{column}{0.7\textwidth}
            \centerline{Model for discrete signal}
            \begin{equation*}
                x[n] = s[n-n_0] + W[n]
            \end{equation*}
            \begin{itemize}
                \item Discrete time-delay is given by $\tau_0=n_0\Delta$
                \item $s[n]$ is non-zero only during pulse length: \\
                    \begin{equation*}
                        x[n] = 
                        \begin{cases}
                            W[n] & , 0 \le n \le n_0-1 \\
                            s[n-n_0]+W[n] & , n_0 \le n < n_0 + M \\
                            W[n] & , n_0 + M \le n \le N
                        \end{cases}
                    \end{equation*}
            \end{itemize}
        \end{column}
    \end{columns}
\end{frame} %>>>

\begin{frame} %<<< 1A.2
    \frametitle{Maximum Likelihood Estimator 2}
    White gaussian noise means $W[n]$ is independent, so the PDF of $s[n;n_0]$
    can be factorized into the PDFs of each sub-interval.
    Split into 3:
    \begin{enumerate}
        \item $x[n]=W[n],\; 0 \le n \le n_0-1$:
            \begin{equation*}
                \prod^{n_0-1}_{n=0}{\frac{1}{\sqrt{2\pi\sigma^2}}
                \exp\left(-\frac{x^2[n]}{2 \sigma^2}\right)}
            \end{equation*}
        \item $x[n]=S\left[n-n_0\right]+W[n], \; n_0 \le n \le n_0+M-1$:
            \begin{equation*}
                \prod^{n_0+M-1}_{n=n_0}{\frac{1}{\sqrt(2\pi\sigma^2)}
                \exp\left(-\frac{\left(x[n]-s[n-n_0]\right)^2}{2\sigma^2}\right)}
            \end{equation*}
        \item $x[n] = W[n], \; n_0+M \le n \le N_1$:
            \begin{equation*}
                \prod^{N-1}_{n=n_0+M}{\frac{1}{\sqrt{2\pi\sigma^2}}
                \exp\left(-\frac{x^2[n]}{2\sigma^2}\right)}
            \end{equation*}
    \end{enumerate}
\end{frame} %>>>

\begin{frame} %<<< 1A.3
    \frametitle{Maximum Likelihood Estimator 3}
    We can expand and factorize 1., 2. \& 3. 
    \begin{gather*}
        P(x; n_0)  = \left(\frac{1}{\sqrt{2\pi\sigma^2}}\right)^{N-1}
        \exp\left(-\frac{\sum^{N-1}_{n=0}{x^2[n]}}{2\sigma^2}\right) \\
        \cdot\exp\left(
            -\frac{1}{2\sigma^2}
            \underbrace{
                \sum^{n_0+M-1}_{n=n_0}{\left(
                        -2x[n]s[n-n_0]+s^2[n-n_0]
                \right)}
            }_{\text{We want to maximize this}}
        \right)
    \end{gather*}
    So we have 
    \begin{equation*}
        \underbrace{2}_{\text{const.}}
        \cdot
        \underbrace{
            \sum^{n_0+M-1}_{n=n_0}{x[n]s[n-n_0]}
        }_{\text{maximize}}
        +
        \underbrace{
            \sum^{n_0+M-1}_{n=n_0}{s^2[n-n_0]}
        }_{\text{not dependent of } n_0}
    \end{equation*}
\end{frame} %>>>

\begin{frame} % <<< Maximum Likelihood Estimator 4
  \frametitle{Maximum Likelihood Estimator 4}
    $s[n]$ is 0 outside of limits so we can expand the sum.
    \begin{equation*}
        \argmax_{n_0}
        \left\{
        \sum^{n_0+M-1}_{n=n_0}{x[n]s[n-n_0]}
        \right\} = 
        \argmax_{n_0}\left\{
            \underbrace{ \sum^{N-1}_{n=0}{x[n]s[n-n_0]} }_{
                \text{This is just a cross correlation}
            }
        \right\}
    \end{equation*}
    We then end up with the Maximum Likelihood Estimator (MLE) to be the
    maximum value of the cross correlation of the signal
    \begin{equation*}
        \widehat{n_0}=\argmax_{0\le m \le N-M}\left\{C_{xs}\left[m\right]\right\} \;\text{ with }\; \widehat{\tau} = \widehat{n_0}\Delta
    \end{equation*}
\end{frame} % >>>

\begin{frame}[fragile] % <<< Implementing the ML estimator
    \frametitle{Implementing the ML estimator}
    We now want to implement the ML esimator.

    Note: Unnecessary code is left out. (Styling and so on). If curious,
    check repo at \href{https://github.com/Dainou01/Studies/tree/main/IN5340/Project2}{here}
    \begin{jllisting}[gobble=8]
        #  Start by getting some packages for this project
        using DSP; using Plots; using Unitful; using MAT
        import Unitful: Time, s, m, Hz
        default(background_color=:transparent, foreground_color=:white)

        # Import the MAT file 
        mat_file = matopen("sonardata2.mat")

        B    = read(mat_file, "B")    * Hz
        fs   = read(mat_file, "fs")   * Hz
        c    = read(mat_file, "c")    * m/s
        T_p  = read(mat_file, "T_p")  * s
        fc   = read(mat_file, "fc")   * Hz
        t_0  = read(mat_file, "t_0")  * s
        data = read(mat_file, "data")
    \end{jllisting}
\end{frame} 
% >>>

\begin{frame}[fragile] % <<< Implementing the ML estimator 2
    \frametitle{Implementing the ML estimator 2}
    Now we can define the signal and plot it over time
    \begin{columns}
        \begin{column}{0.5\textwidth}
            \begin{jllisting}[gobble=16]
                # Signal model
                α = B / T_p

                s_Tx(t::Time) = (-T_p/2<=t<=T_p/2) 
                    ? exp(2π*α*t^2/2*im) : 0.0im
                # Convert any input to Time
                s_Tx(t) = s_Tx(t*s) 

                # Plot simple signal
                t = -T_p/2 : 1/fs : T_p/2
                plot(t,real.(s_Tx.(t)))
                plot!(t, imag.(s_Tx.(t)))
            \end{jllisting}
        \end{column}
        \begin{column}{0.5\textwidth}
            Plotted output
            \begin{figure}
                \includesvg[width=\columnwidth]{"../1b.svg"}
            \end{figure}
        \end{column}
    \end{columns}
\end{frame}
% >>>

\begin{frame}[fragile] % <<< Implementing the ML estimator 3
    \frametitle{Implementing the ML estimator 3}
    Now we implement the xcorr operation...
    \begin{jllisting}[gobble=8]
        match_filter(ch,signal) = xcorr(ch, signal, padmode=:longest)[end÷2+1:end]
    \end{jllisting}
    and we test it by applying it to 1 channel and the source signal
    \begin{columns}
        \begin{column}{0.53\textwidth}
            \begin{jllisting}[gobble=16]
                ml₁ = match_filter(data[:, 1], s_Tx.(t))
                plot(
                    axes(ml₁,1)/upreferred(fs),
                    abs.(ml₁),
                )
            \end{jllisting}
        \end{column}
        \begin{column}{0.47\textwidth}
            \begin{figure}
                Plot generated from code
                \includesvg[width=\columnwidth]{"../1b2.svg"}
            \end{figure}
        \end{column}
    \end{columns}
\end{frame}
% >>>

\begin{frame}[fragile] % <<< Applying the ML estimator
    \frametitle{Applying the ML estimator}
    Now we map this as a function on each channel and plot the results.
    \begin{jllisting}[gobble=8]
        compressed = mapslices(
            ch -> match_filter(ch, s_Tx.(t)),
            data[1:1600,:], dims=(1,)) 

        heatmap(axes(compressed,2), axes(compressed,1)/upreferred(fs), 
            amp2db.(abs.(compressed)/maximum(abs.(compressed))))
        plot([
            plot((1:1600)/upreferred(fs), abs.(d[1:1600,1]))
            for d in [data, compressed]
        ]..., layout=[1,1],)
    \end{jllisting}
    \begin{figure}
        \centering
        \begin{subfigure}{0.5\textwidth}
            \centering
            \includesvg[width=\textwidth]{"../1c.svg"}
        \end{subfigure}%
        \begin{subfigure}{0.5\textwidth}
            \centering
            \includesvg[width=\columnwidth]{"../1c2.svg"}
        \end{subfigure}
    \end{figure}
\end{frame}
% >>>

\begin{frame} % <<< Applying the ML estimator 2
    \frametitle{Applying the ML estimator 2}
    \begin{itemize}
        \item Looking at the 1600 samples of the raw data, we see that it looksquite noisy,
            but there seems to be some kind of signal around 0.01s. 

        \item When we perform the cross correlation, we see that a strong peak appear at
            about 5ms. By the ML estimator this is when it is most likely when we
            recieve the pulse.
    \end{itemize}
    \begin{figure}
        \centering
        \begin{subfigure}{0.5\textwidth}
            \centering
            \includesvg[width=\textwidth]{"../1c.svg"}
        \end{subfigure}%
        \begin{subfigure}{0.5\textwidth}
            \centering
            \includesvg[width=\columnwidth]{"../1c2.svg"}
        \end{subfigure}
    \end{figure}
\end{frame} % >>>

\begin{frame}[fragile] % <<< Estimate time delay using ML
    \frametitle{Estimate time delay using ML}
    We now want to estimate the time delay across all channels of the first 1600
    samples using the ML estimator. 
    \begin{jllisting}[gobble=8]
        match_filter(ch,signal) = xcorr(ch, signal, padmode=:longest)[end÷2+1:end] 
        mle(ch, signal) = match_filter(ch, signal) .|> abs |> argmax
        s0 = s_Tx.(t)
        # Resample the signals
        s4 = resample(s0, 4, dims=(1,))
        s8 = resample(s0, 8, dims=(1,))

        data_x0 = data[1:1600,:]
        # Resample the data
        data_x4 = resample(data[1:1600,:], 4, dims=(1,))
        data_x8 = resample(data[1:1600,:], 8, dims=(1,))

        # Perform mle on each channel 
        τₓ₀ = mapslices(x -> mle(x, s0), data_x0, dims=(1,))
        τₓ₄ = mapslices(x -> mle(x, s4), data_x4, dims=(1,))
        τₓ₈ = mapslices(x -> mle(x, s8), data_x8, dims=(1,))
    \end{jllisting}
\end{frame}
% >>>

\begin{frame} % <<< Estimate time delay usin ML 2
    \frametitle{Estimate time delay usin ML 2}
    \begin{figure}
        \includesvg[height=0.4\textheight]{"../1d.svg"}
    \end{figure}
    \begin{itemize}
        \item We can see that upsampling allows the estimator to evaluate the
            time delay with more points. We can see this in how the 1x sample
            snapps to 0.01ms which corresponds with the sampling frequency,
            while the other allows the timedelay to be estimated at 4x and 8x
            the sampling frequency respectively.
    \end{itemize}
\end{frame} % >>>

\begin{frame}[fragile] % <<<  Cramér-Rao Lower Bound of time delay 
    \frametitle{ Cramér-Rao Lower Bound of time delay }
    We now want to apply the CRLB on the time delay estimator. I choose to
    find the CRLB using the SNR of the match filtered data. We have that the
    CRLB is implemented by

    \begin{gather*}
        \Var\left\{\hat{\tau_0}\right\} = \frac{1}{\text{SNR}\cdot \beta^2_\text{rms}}
    \end{gather*}
    
    I start by finding $\beta^2_\text{rms}$ and the SNR.

    \begin{jllisting}[gobble=8]
        # β²ᵣₘₛ is streight forward
        β²ᵣₘₛ = (2π)^2*fc^2

        # Map a function that gets the value of the peak, on each channel
        Signal = map(ch -> abs.(compressed[τₓ₀[ch], ch]), 1:32)
        # Map a function that gets the value of each sample except the peak, 
        # on each channel. Then, pass channel to mean.
        Noise =  map(ch -> abs.(compressed[1:1600 .!= τₓ₀[ch], ch]), 1:32) .|> mean

        SNR = Signal./Noise
    \end{jllisting}
\end{frame}
% >>>

\begin{frame}[fragile] % <<< Cramér-Rao Lower Bound of time delay 2
    \frametitle{Cramér-Rao Lower Bound of time delay 2}
    With each factor of the descriminator found, get the CRLB and plot it per channel
    \begin{columns}
        \begin{column}{0.5\textwidth}
            \begin{jllisting}[gobble=16]
                CRLB = 1 ./ (SNR.*β²ᵣₘₛ)
                std = sqrt.(CRLB) .|> toUnit(u"µs")
                plot(std)

                waveperiod = 1/fc |> toUnit(u"µs")
                res = [minimum(std)/waveperiod, 
                       maximum(std)/waveperiod]
                @printf "Lower limit for accuracy: 
                        (%.3f - %.3f) wave periods" 
                        res...
                # -> Lower limit for accuracy: (0.029 - 0.035) wave periods
            \end{jllisting}
        \end{column}
        \begin{column}{0.5\textwidth}
            \begin{figure}
                \includesvg[width=\textwidth]{"../2.svg"}
            \end{figure}
        \end{column}
    \end{columns}
    We see that not every channel has the same accuracy, and that is fluctuates
    between 0.029 and 0.035 wave periods.
\end{frame}
% >>>

\begin{frame} % <<< Cramér-Rao Lower Bound of time delay 3
    \frametitle{Cramér-Rao Lower Bound of time delay 3}
    Overlaying the plot of $\tau_0$ per channel, we get the following plot.
    \begin{columns}
        \begin{column}{0.5\textwidth}
            We can see that the CRLB dips, for the channels at the center of
            time delay estimate "step". 

            I interpret this as the estimator to be
            more accurate at the channels in the center of each step while the
            transitions where the estimate changes, is more inaccurate. 
        \end{column}
        \begin{column}{0.5\textwidth}
            \begin{figure}
                \includesvg[width=\textwidth]{"../2b.svg"}
            \end{figure}
        \end{column}
    \end{columns}
\end{frame} % >>>

\begin{frame}[fragile] % <<< Least Squares Estimation
    \frametitle{Least Squares Estimation}
    Implementing the least squares estimator by using the algorithm from lecture 5.
    \begin{itemize}
        \item Upsample by 8 to get the more samples around the peak
            \begin{jllisting}[gobble=16]
                upsample = 8
                x = resample(compressed[:,1], upsample) .|> abs .|> x->x^2
                N = size(x,1)
            \end{jllisting}
        \item Select the samples that are around the peak of the signal
            \begin{jllisting}[gobble=16]
                # Index 1:N on boolian check
                fwhm_filter = x .>= 0.5maximum(x)
                fwhm_t = ((1:N)./(upsample*fs))[fwhm_filter] .|> toUnit(u"ms")
                fwhm_x = x[fwhm_filter] .|> log
            \end{jllisting}

        \item Create observation matrix and perform the least squares fit
            \begin{jllisting}[gobble=16]
                H = [r^c for r=fwhm_t, c=0:2]
                θ = ustrip(H) \ fwhm_x ./ unit.(H[1,:])
                # '\' doesn't work with units yet, so using 'ustrip' to remove units from H and 'unit' to reapply units to result
            \end{jllisting}
    \end{itemize}
\end{frame}
% >>>

\begin{frame}[fragile] % <<< Least Squares Estimation 2
    \frametitle{Least Squares Estimation 2}
    \begin{itemize}
        \item Using the parameter $\hat{\theta}$, we calculate the time delay, pulse width and intensity
            \begin{jllisting}[gobble=16]
                σ = sqrt(-1/(2θ[3]))         # -> 0.0143ms
                τ = -θ[2] / 2θ[3]            # -> 3.5494ms
                I = exp(θ[1] - θ[2]^2/4θ[3]) # -> 6.5722e6
            \end{jllisting}
    \end{itemize}
    \begin{columns}
        \begin{column}{0.5\textwidth}
        \pin Lastly, recostruct a gaussian with the specified parameters
            \begin{jllisting}[gobble=16]
                g(t) = I*exp(-(t-τ)^2/(2σ^2))
            \end{jllisting}
            Plotting the signal around the peak, we have the following plot
        \end{column}
        \begin{column}{0.5\textwidth}
            \begin{figure}
                \includesvg[width=\columnwidth]{"../3a.svg"}
            \end{figure}
        \end{column}
    \end{columns}

\end{frame}
% >>>

\begin{frame}[fragile] % <<< Least Squares Estimation 3
    \frametitle{Least Squares Estimation 3}
    Wrapping it into a function of samples, which returns
    the parameters ...
    \begin{jllisting}[gobble=8]
        function lse(samples, upsample=8)
            x = resample(samples, upsample)
            N = size(x, 1)

            fwhm_filter = x .>= 0.5maximum(x)
            fwhm_t = ((1:N) ./ (upsample*fs))[fwhm_filter] .|> toUnit(u"ms")
            fwhm_x = x[fwhm_filter] .|> log

            H = [r^c for r=fwhm_t, c=0:2]
            θ = ustrip(H) \ fwhm_x ./ unit.(H[1,:])
            return sqrt(-1/(2θ[3])), -θ[2] / 2θ[3], exp(θ[1] - θ[2]^2/4θ[3])
        end
    \end{jllisting}
    allows us to map the {\texttt lse} function onto the compressed data as a
    function of the channels
    \begin{jllisting}[gobble=8]
        τ_lse = mapslices(
            ch -> lse(ch)[2], # For each channel, get the 2nd parameter from lse
            compressed,
            dims=1
        )
    \end{jllisting}
\end{frame}
% >>>

\begin{frame} % <<< Least Squares Estimation 4
    \frametitle{Least Squares Estimation 4}
    \begin{columns}
        \begin{column}{0.5\textwidth}
            \begin{itemize}
                \item We see that the time delay estimate is larger for later channels.
                \item Comparing the time delay from LSE to that of the MSE, we see
                    that the MSE stagger between channels, while the LSE is a lot smoother.
                \item MSE estimates the time delay to be the most likely sample at which
                    it can occur
                \item LSE interpolates the time delay to be a best possible fit to a quadratic polynomial.
            \end{itemize}
        \end{column}
        \begin{column}{0.5\textwidth}
            \begin{figure}
                \includesvg[width=0.9\columnwidth]{"../3b.svg"}
            \end{figure}
            \begin{figure}
                \includesvg[width=0.9\columnwidth]{"../3b2.svg"}
            \end{figure}
        \end{column}
    \end{columns}
\end{frame} % >>>

\end{document}
